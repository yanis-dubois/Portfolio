<!DOCTYPE html><!--ngOq_SpwJEC3wOcs8SgIt--><html lang="fr"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/Portfolio/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/Portfolio/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/lineDetect.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png"/><link rel="stylesheet" href="/Portfolio/_next/static/chunks/bd89afa1177e069e.css" data-precedence="next"/><link rel="stylesheet" href="/Portfolio/_next/static/chunks/46c31b84835d34d9.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/Portfolio/_next/static/chunks/c85a7d07e7b82c9a.js"/><script src="/Portfolio/_next/static/chunks/89fec6e6de8a2578.js" async=""></script><script src="/Portfolio/_next/static/chunks/7880f8283a6f3daf.js" async=""></script><script src="/Portfolio/_next/static/chunks/5349511ac2282d68.js" async=""></script><script src="/Portfolio/_next/static/chunks/turbopack-fa6bc77bb000209b.js" async=""></script><script src="/Portfolio/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js" async=""></script><script src="/Portfolio/_next/static/chunks/c6ac08833fb371d7.js" async=""></script><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png"/><meta name="next-size-adjust" content=""/><title>Portfolio - Yanis Dubois</title><meta name="description" content="Generated by create next app"/><meta name="robots" content="noindex, nofollow"/><script src="/Portfolio/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen text-light"><nav class="bg-dark-deep/70 backdrop-blur-sm border-b border-light-soft/10 sticky top-0 w-full p-2 text-light-soft z-5 flex justify-between"><div class="pl-2"><a href="/Portfolio">🏠 <span class="hover:underline hover:text-light">Accueil</span></a><span class="text-light-dark"> / </span><a href=""><span>📚<!-- --> </span><span class="hover:underline hover:text-light">Analyse de bibliothèque</span></a></div><div class="pr-2"><div><div class="cursor-pointer flex justify-center text-light-soft"><p>⚙️ <span class="pr-1">Autres projets</span></p><div class="transition-transform duration-300 ease-out rotate-0">▸</div></div></div></div></nav><div id="nav-portal-root"></div><header class="bg-dark-soft text-light"><div class=""><div class="p-6 mx-auto max-w-5xl " style="clip-path:inset(0 0 0 0)"><h1 class="text-5xl font-bold text-center">📚<!-- --> <!-- -->Analyse de bibliothèque</h1></div></div></header><main><div class="bg-dark text-light-soft relative flex"><aside class="hidden lg:flex sticky top-46 h-[calc(100vh-20rem)] items-center"><div class="max-h-full overflow-hidden px-2 space-y-3 pl-6
          transition-opacity duration-300 ease-out
          opacity-100
          "></div><nav class="max-h-[70vh] w-[250px] fixed top-1/2 -translate-y-1/2 overflow-y-auto 
          bg-dark border border-light-soft/10 rounded-2xl shadow-md 
          ml-4 p-2 pt-4 pb-4 text-sm space-y-2 z-1
          transition-all duration-300 ease-out transform
          opacity-0 -translate-x-4 pointer-events-none
          "><ul class="space-y-1"></ul></nav></aside><div class="p-6 mx-auto max-w-5xl project" style="clip-path:inset(0 0 0 0)"><div><h1>Contexte</h1><hr/><div><div><p>Ce projet a été réalisé dans le cadre de mon stage de fin d’études, au sein de l’IUT d’informatique de Gradignan. L’objectif principal était de développer une application capable de scanner et d’analyser des photographies de bibliothèques (étagères remplies de livres), afin d’identifier automatiquement les ouvrages présents à partir des images.</p><p>Le sujet m’a été proposé par Mathieu Raffinot, chercheur au CNRS, avec qui j’ai collaboré tout au long du stage.</p></div><div><figure><a href="/images/projects/bookshelfAnalysis/lineDetect.png"><img src="/images/projects/bookshelfAnalysis/lineDetect.png"/></a></figure></div></div><h1>Idée générale</h1><hr/><h2>Introduction</h2><p>Ce projet était séparé en deux parties :</p><ol type="1" start="1"><li>La première consistait à concevoir une méthode de segmentation et d’analyse d’images de bibliothèques dans le but d’identifier automatiquement les ouvrages présents, notamment à partir de leurs tranches.</li></ol><ol type="1" start="2"><li>La seconde portait sur une tâche plus spécifique : la modification de la police d’écriture utilisée dans une application mobile Android existante, dans un souci d’accessibilité.</li></ol><h2>1. Analyse de bibliothèque</h2><p>La suite présente le prototype Python développé au cours du projet, en détaillant les différentes étapes clés du pipeline de traitement d’images.</p><h3>1.1 Recadrage de l’image</h3><p>La première étape du processus consistait à corriger l’orientation des images afin que les étagères apparaissent bien alignées horizontalement. Pour cela, j’ai mis en œuvre des algorithmes de détection de lignes, notamment le filtre de Canny suivi de la transformée de Hough. Ces lignes détectées permettent d’estimer l’inclinaison de l’image par rapport à l’horizontale, et une rotation est ensuite appliquée pour réaligner correctement l’ensemble de la scène.</p><div class="grid gap-6 md:grid-cols-2"><div><figure><a href="/images/projects/bookshelfAnalysis/lineDetect.png"><img src="/images/projects/bookshelfAnalysis/lineDetect.png"/></a><figcaption>Détection de lignes</figcaption></figure></div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png"/></a><figcaption>Rotation</figcaption></figure></div></div><h3>1.2 Séparation des rangées de livres</h3><p>Une fois l’image redressée, l’objectif suivant était d’isoler les différentes rangées de livres présentes sur les étagères. Pour ce faire, les mêmes techniques de détection de lignes horizontales ont été utilisées. Les coordonnées de ces lignes servent de repères pour découper l’image en plusieurs zones correspondant aux différentes étagères.</p><div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png"/></a><figcaption>Détection de lignes horizontales</figcaption></figure></div><div class="grid gap-6 md:grid-cols-2"><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png"/></a><figcaption>Première partie de la segmentation</figcaption></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png"/></a><figcaption>Seconde partie de la segmentation</figcaption></figure></div></div><h3>1.3 Séparation des tranches de livres</h3><p>L’étape suivante visait à segmenter chaque rangée afin d’identifier individuellement les tranches de livres. Là encore, des méthodes similaires de détection de lignes, cette fois verticales, ont été appliquées pour localiser les limites entre chaque ouvrage. L’image est ensuite découpée en sous-parties correspondant à chaque tranche.</p><div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png"/></a><figcaption>Détection des lignes</figcaption></figure><h3>1.4 Nettoyage de la segmentation</h3></div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png"/></a><figcaption>Quelques tranches de livre résultats</figcaption></figure></div></div><p>Une phase de traitement supplémentaire a été nécessaire pour affiner les résultats et éliminer les éléments indésirables ou parasites (fonds, ombres, objets non pertinents). Ce nettoyage repose lui aussi sur des algorithmes de détection de structures linéaires, combinés à des heuristiques pour filtrer les segments incohérents.</p><div class="grid gap-6 md:grid-cols-2"><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png"/></a><figcaption>Avant nettoyage</figcaption></figure></div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png"/></a><figcaption>Après nettoyage</figcaption></figure></div></div><h3>1.5 Extraction du texte</h3><p>Une fois les tranches correctement isolées, l’étape suivante consistait à extraire le texte visible sur celles-ci. J’ai utilisé le moteur OCR Tesseract, appliqué sur plusieurs versions binarisées de chaque images de tranche, avec différents seuils de contraste. Cette approche multi-seuils permet de maximiser les chances d’extraire les informations utiles, en contournant les variations de qualité ou de lisibilité du texte imprimé.</p><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png"/></a><figcaption>Image originale</figcaption></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png"><img src="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png"/></a></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png"><img src="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png"/></a></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png"><img src="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png"/></a></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png"><img src="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png"/></a><figcaption>Image binaire avec différents seuils</figcaption></figure><p>Résultats obtenus :</p><blockquote>© | Gintbendee cxrangice Un tout petit monde David Lodge <br/>S | Bionteneoce ttrangere Un tout petit monde David Lodge<br/>Resse tian Un tout petit monde David LodgeHats<br/>g | Reaves mate Un tout petit monde David LodgeBibhotheque etrangere</blockquote><h3>1.6 Traitement des résultats textuels</h3><p>Le texte brut issu de l’OCR contient souvent du bruit : erreurs de reconnaissance, caractères spéciaux, coupures. Un post-traitement a donc été mis en place pour nettoyer ces résultats. Il comprend la suppression des caractères non alphanumériques, ainsi qu’un filtrage destiné à isoler les chaînes de texte les plus pertinentes.</p><p>Résultats obtenus :</p><blockquote>Un tout petit monde David Lodge</blockquote><h3>1.7 Validation via interrogation en ligne</h3><p>Afin de s’assurer d’avoir une information viable, on a ensuite décidé d’interroger Google en utilisant Selenium, ce qui nous a permis de naviguer en headless sur internet. On crée une requête avec Selenium contenant le résultat obtenu dans l’étape précédente, et l’on reçoit alors le titre exacte accompagné du nom de l’auteur.</p><p>Pour fiabiliser les informations extraites, une validation automatique a été ajoutée en fin de chaîne. À l’aide de Selenium, une requête web est générée à partir du texte obtenu, puis envoyée à Google en mode headless. La réponse est ensuite analysée afin de récupérer le titre exact de l’ouvrage, ainsi que, lorsque c’est possible, le nom de l’auteur. Cette étape permet de compenser les éventuelles erreurs de l’OCR en s’appuyant sur des sources d’information externes.</p><h2>2. Changement de police d’écriture</h2><p>La seconde partie du projet consistait à ajouter une fonctionnalité de personnalisation de la police d’écriture dans l’application open source TextFairy, dédiée à la reconnaissance optique de caractères (OCR) sur Android.</p><p>Bien que cette tâche puisse paraître simple en apparence, elle s’est révélée plus technique qu’anticipé, en raison de la complexité de l’architecture de l’application et des spécificités du développement Android. Le travail a été réalisé sous Android Studio, en manipulant les ressources d’interface, les fichiers XML de styles, et les mécanismes de gestion de thèmes pour intégrer le changement de typographie de manière propre et fonctionnelle.</p><div class="grid gap-6 md:grid-cols-2"><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png"/></a><figcaption>Avant application de la police</figcaption></figure></div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png"/></a><figcaption>Après application de la police</figcaption></figure></div></div><h1>Ressources supplémentaires</h1><hr/></div><div class="grid gap-6 md:grid-cols-2"><div class="font-bold text-light text-center"><a class="flex justify-center items-center" href="https://github.com/yanis-dubois/BookShelfAnalyse"><img alt="" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="w-[1rem] h-[1rem]" style="color:transparent" src="/images/icons/Git_icon.png"/> <span class="underline">Accédez au code source →</span></a></div><div class="font-bold text-light text-center"><a href="https://drive.google.com/file/d/1A0NbOEAv3ft5B_GCygAvZErcZi5LReBw/view?usp=share_link">📄<!-- --> <span class="underline">Consultez le rapport PDF →</span></a></div></div></div></div></main><footer class="bg-dark-soft p-6 text-center text-sm text-light-dark">© 2025 Yanis Dubois — Libre et Open Source, hébergé via GitHub Pages<br/>Crédits : image #Compétences - Unsplash ; image #Loisirs - Scavengers Reign par Joseph Bennett et Charles Huettner</footer></div><!--$--><!--/$--><script src="/Portfolio/_next/static/chunks/c85a7d07e7b82c9a.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[39756,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"default\"]\n3:I[37457,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"default\"]\n4:I[22016,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\"],\"default\"]\n5:I[72334,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\"],\"ProjectsNav\"]\n6:I[72334,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\"],\"TableOfContents\"]\n38:I[68027,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"default\"]\n:HL[\"/Portfolio/_next/static/chunks/bd89afa1177e069e.css\",\"style\"]\n:HL[\"/Portfolio/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/Portfolio/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/Portfolio/_next/static/chunks/46c31b84835d34d9.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"ngOq-SpwJEC3wOcs8SgIt\",\"p\":\"/Portfolio\",\"c\":[\"\",\"projects\",\"bookshelfAnalysis\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"projects\",{\"children\":[\"bookshelfAnalysis\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Portfolio/_next/static/chunks/bd89afa1177e069e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"fr\",\"children\":[\"$\",\"body\",null,{\"className\":\"geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"projects\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"bookshelfAnalysis\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen text-light\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"bg-dark-deep/70 backdrop-blur-sm border-b border-light-soft/10 sticky top-0 w-full p-2 text-light-soft z-5 flex justify-between\",\"children\":[[\"$\",\"div\",null,{\"className\":\"pl-2\",\"children\":[[\"$\",\"$L4\",null,{\"href\":\"/\",\"children\":[\"🏠 \",[\"$\",\"span\",null,{\"className\":\"hover:underline hover:text-light\",\"children\":\"Accueil\"}]]}],[\"$\",\"span\",null,{\"className\":\"text-light-dark\",\"children\":\" / \"}],[\"$\",\"$L4\",null,{\"href\":\"\",\"children\":[[\"$\",\"span\",null,{\"children\":[\"📚\",\" \"]}],[\"$\",\"span\",null,{\"className\":\"hover:underline hover:text-light\",\"children\":\"Analyse de bibliothèque\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"pr-2\",\"children\":[\"$\",\"$L5\",null,{}]}]]}],[\"$\",\"div\",null,{\"id\":\"nav-portal-root\"}],[\"$\",\"header\",null,{\"className\":\"bg-dark-soft text-light\",\"children\":[\"$\",\"div\",null,{\"className\":\"\",\"style\":{},\"id\":\"$undefined\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-6 mx-auto max-w-5xl \",\"style\":{\"clipPath\":\"inset(0 0 0 0)\"},\"children\":[\"$\",\"h1\",null,{\"className\":\"text-5xl font-bold text-center\",\"children\":[\"📚\",\" \",\"Analyse de bibliothèque\"]}]}]}]}],[\"$\",\"main\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"bg-dark text-light-soft relative flex\",\"style\":{},\"id\":\"$undefined\",\"children\":[[\"$\",\"$L6\",null,{}],[\"$\",\"div\",null,{\"className\":\"p-6 mx-auto max-w-5xl project\",\"style\":{\"clipPath\":\"inset(0 0 0 0)\"},\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h1\",null,{\"children\":\"Contexte\"}],[\"$\",\"hr\",null,{}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"p\",null,{\"children\":\"Ce projet a été réalisé dans le cadre de mon stage de fin d’études, au sein de l’IUT d’informatique de Gradignan. L’objectif principal était de développer une application capable de scanner et d’analyser des photographies de bibliothèques (étagères remplies de livres), afin d’identifier automatiquement les ouvrages présents à partir des images.\"}],\"$L7\"]}],\"$L8\"]}],\"$L9\",\"$La\",\"$Lb\",\"$Lc\",\"$Ld\",\"$Le\",\"$Lf\",\"$L10\",\"$L11\",\"$L12\",\"$L13\",\"$L14\",\"$L15\",\"$L16\",\"$L17\",\"$L18\",\"$L19\",\"$L1a\",\"$L1b\",\"$L1c\",\"$L1d\",\"$L1e\",\"$L1f\",\"$L20\",\"$L21\",\"$L22\",\"$L23\",\"$L24\",\"$L25\",\"$L26\",\"$L27\",\"$L28\",\"$L29\",\"$L2a\",\"$L2b\",\"$L2c\",\"$L2d\",\"$L2e\",\"$L2f\",\"$L30\",\"$L31\"]}],\"$L32\"]}]]}]}],\"$L33\"]}],[\"$L34\",\"$L35\"],\"$L36\"]}],{},null,false]},null,false]},null,false]},null,false],\"$L37\",false]],\"m\":\"$undefined\",\"G\":[\"$38\",[\"$L39\"]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"3a:I[5500,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\"],\"Image\"]\n3b:I[97367,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"OutletBoundary\"]\n3d:I[11533,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"AsyncMetadataOutlet\"]\n3f:I[97367,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"ViewportBoundary\"]\n41:I[97367,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"MetadataBoundary\"]\n42:\"$Sreact.suspense\"\n7:[\"$\",\"p\",null,{\"children\":\"Le sujet m’a été proposé par Mathieu Raffinot, chercheur au CNRS, avec qui j’ai collaboré tout au long du stage.\"}]\n8:[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/lineDetect.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/lineDetect.png\"}]}]}]}]\n9:[\"$\",\"h1\",null,{\"children\":\"Idée générale\"}]\na:[\"$\",\"hr\",null,{}]\nb:[\"$\",\"h2\",null,{\"children\":\"Introduction\"}]\nc:[\"$\",\"p\",null,{\"children\":\"Ce projet était séparé en deux parties :\"}]\nd:[\"$\",\"ol\",null,{\"type\":\"1\",\"start\":\"1\",\"children\":[\"$\",\"li\",null,{\"children\":\"La première consistait à concevoir une méthode de segmentation et d’analyse d’images de bibliothèques dans le but d’identifier automatiquement les ouvrages présents, notamment à partir de leurs tranches.\"}]}]\ne:[\"$\",\"ol\",null,{\"type\":\"1\",\"start\":\"2\",\"children\":[\"$\",\"li\",null,{\"children\":\"La seconde portait sur une tâche plus spécifique : la modification de la police d’écriture utilisée dans une application mobile Android existante, dans un souci d’accessibilité.\"}]}]\nf:[\"$\",\"h2\",null,{\"children\":\"1. Analyse de bibliothèque\"}]\n10:[\"$\",\"p\",null,{\"children\":\"La suite présente le prototype Python développé"])</script><script>self.__next_f.push([1," au cours du projet, en détaillant les différentes étapes clés du pipeline de traitement d’images.\"}]\n11:[\"$\",\"h3\",null,{\"children\":\"1.1 Recadrage de l’image\"}]\n12:[\"$\",\"p\",null,{\"children\":\"La première étape du processus consistait à corriger l’orientation des images afin que les étagères apparaissent bien alignées horizontalement. Pour cela, j’ai mis en œuvre des algorithmes de détection de lignes, notamment le filtre de Canny suivi de la transformée de Hough. Ces lignes détectées permettent d’estimer l’inclinaison de l’image par rapport à l’horizontale, et une rotation est ensuite appliquée pour réaligner correctement l’ensemble de la scène.\"}]\n"])</script><script>self.__next_f.push([1,"13:[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/lineDetect.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/lineDetect.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Détection de lignes\"}]]}]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Rotation\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"14:[\"$\",\"h3\",null,{\"children\":\"1.2 Séparation des rangées de livres\"}]\n15:[\"$\",\"p\",null,{\"children\":\"Une fois l’image redressée, l’objectif suivant était d’isoler les différentes rangées de livres présentes sur les étagères. Pour ce faire, les mêmes techniques de détection de lignes horizontales ont été utilisées. Les coordonnées de ces lignes servent de repères pour découper l’image en plusieurs zones correspondant aux différentes étagères.\"}]\n"])</script><script>self.__next_f.push([1,"16:[\"$\",\"div\",null,{\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Détection de lignes horizontales\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Première partie de la segmentation\"}]]}],[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Seconde partie de la segmentation\"}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"17:[\"$\",\"h3\",null,{\"children\":\"1.3 Séparation des tranches de livres\"}]\n18:[\"$\",\"p\",null,{\"children\":\"L’étape suivante visait à segmenter chaque rangée afin d’identifier individuellement les tranches de livres. Là encore, des méthodes similaires de détection de lignes, cette fois verticales, ont été appliquées pour localiser les limites entre chaque ouvrage. L’image est ensuite découpée en sous-parties correspondant à chaque tranche.\"}]\n"])</script><script>self.__next_f.push([1,"19:[\"$\",\"div\",null,{\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Détection des lignes\"}]]}],[\"$\",\"h3\",null,{\"children\":\"1.4 Nettoyage de la segmentation\"}]]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Quelques tranches de livre résultats\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"1a:[\"$\",\"p\",null,{\"children\":\"Une phase de traitement supplémentaire a été nécessaire pour affiner les résultats et éliminer les éléments indésirables ou parasites (fonds, ombres, objets non pertinents). Ce nettoyage repose lui aussi sur des algorithmes de détection de structures linéaires, combinés à des heuristiques pour filtrer les segments incohérents.\"}]\n"])</script><script>self.__next_f.push([1,"1b:[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Avant nettoyage\"}]]}]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Après nettoyage\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"1c:[\"$\",\"h3\",null,{\"children\":\"1.5 Extraction du texte\"}]\n1d:[\"$\",\"p\",null,{\"children\":\"Une fois les tranches correctement isolées, l’étape suivante consistait à extraire le texte visible sur celles-ci. J’ai utilisé le moteur OCR Tesseract, appliqué sur plusieurs versions binarisées de chaque images de tranche, avec différents seuils de contraste. Cette approche multi-seuils permet de maximiser les chances d’extraire les informations utiles, en contournant les variations de qualité ou de lisibilité du texte imprimé.\"}]\n1e:[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Image originale\"}]]}]\n1f:[\"$\",\"figure\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png\"}]}]}]\n20:[\"$\",\"figure\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png\"}]}]}]\n21:[\"$\",\"figure\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png\"}]}]}]\n22:[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Image binaire avec différents seuils\"}]]}]\n23:[\"$\",\"p\",null,{\"children\":\"Résultats obtenus :\"}]\n24:[\"$\",\"blockquote\",null,{\"children\":[\"© | Gintbendee cxran"])</script><script>self.__next_f.push([1,"gice Un tout petit monde David Lodge \",[\"$\",\"br\",null,{}],\"S | Bionteneoce ttrangere Un tout petit monde David Lodge\",[\"$\",\"br\",null,{}],\"Resse tian Un tout petit monde David LodgeHats\",[\"$\",\"br\",null,{}],\"g | Reaves mate Un tout petit monde David LodgeBibhotheque etrangere\"]}]\n25:[\"$\",\"h3\",null,{\"children\":\"1.6 Traitement des résultats textuels\"}]\n26:[\"$\",\"p\",null,{\"children\":\"Le texte brut issu de l’OCR contient souvent du bruit : erreurs de reconnaissance, caractères spéciaux, coupures. Un post-traitement a donc été mis en place pour nettoyer ces résultats. Il comprend la suppression des caractères non alphanumériques, ainsi qu’un filtrage destiné à isoler les chaînes de texte les plus pertinentes.\"}]\n27:[\"$\",\"p\",null,{\"children\":\"Résultats obtenus :\"}]\n28:[\"$\",\"blockquote\",null,{\"children\":\"Un tout petit monde David Lodge\"}]\n29:[\"$\",\"h3\",null,{\"children\":\"1.7 Validation via interrogation en ligne\"}]\n2a:[\"$\",\"p\",null,{\"children\":\"Afin de s’assurer d’avoir une information viable, on a ensuite décidé d’interroger Google en utilisant Selenium, ce qui nous a permis de naviguer en headless sur internet. On crée une requête avec Selenium contenant le résultat obtenu dans l’étape précédente, et l’on reçoit alors le titre exacte accompagné du nom de l’auteur.\"}]\n2b:[\"$\",\"p\",null,{\"children\":\"Pour fiabiliser les informations extraites, une validation automatique a été ajoutée en fin de chaîne. À l’aide de Selenium, une requête web est générée à partir du texte obtenu, puis envoyée à Google en mode headless. La réponse est ensuite analysée afin de récupérer le titre exact de l’ouvrage, ainsi que, lorsque c’est possible, le nom de l’auteur. Cette étape permet de compenser les éventuelles erreurs de l’OCR en s’appuyant sur des sources d’information externes.\"}]\n2c:[\"$\",\"h2\",null,{\"children\":\"2. Changement de police d’écriture\"}]\n2d:[\"$\",\"p\",null,{\"children\":\"La seconde partie du projet consistait à ajouter une fonctionnalité de personnalisation de "])</script><script>self.__next_f.push([1,"la police d’écriture dans l’application open source TextFairy, dédiée à la reconnaissance optique de caractères (OCR) sur Android.\"}]\n2e:[\"$\",\"p\",null,{\"children\":\"Bien que cette tâche puisse paraître simple en apparence, elle s’est révélée plus technique qu’anticipé, en raison de la complexité de l’architecture de l’application et des spécificités du développement Android. Le travail a été réalisé sous Android Studio, en manipulant les ressources d’interface, les fichiers XML de styles, et les mécanismes de gestion de thèmes pour intégrer le changement de typographie de manière propre et fonctionnelle.\"}]\n"])</script><script>self.__next_f.push([1,"2f:[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Avant application de la police\"}]]}]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Après application de la police\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"30:[\"$\",\"h1\",null,{\"children\":\"Ressources supplémentaires\"}]\n31:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"32:[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"font-bold text-light text-center\",\"children\":[\"$\",\"$L4\",null,{\"href\":\"https://github.com/yanis-dubois/BookShelfAnalyse\",\"className\":\"flex justify-center items-center\",\"children\":[[\"$\",\"$L3a\",null,{\"src\":\"/images/icons/Git_icon.png\",\"alt\":\"\",\"width\":32,\"height\":32,\"className\":\"w-[1rem] h-[1rem]\"}],\" \",[\"$\",\"span\",null,{\"className\":\"underline\",\"children\":\"Accédez au code source →\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"font-bold text-light text-center\",\"children\":[\"$\",\"$L4\",null,{\"href\":\"https://drive.google.com/file/d/1A0NbOEAv3ft5B_GCygAvZErcZi5LReBw/view?usp=share_link\",\"children\":[\"📄\",\" \",[\"$\",\"span\",null,{\"className\":\"underline\",\"children\":\"Consultez le rapport PDF →\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"33:[\"$\",\"footer\",null,{\"className\":\"bg-dark-soft p-6 text-center text-sm text-light-dark\",\"children\":[\"© 2025 Yanis Dubois — Libre et Open Source, hébergé via GitHub Pages\",[\"$\",\"br\",null,{}],\"Crédits : image #Compétences - Unsplash ; image #Loisirs - Scavengers Reign par Joseph Bennett et Charles Huettner\"]}]\n34:[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Portfolio/_next/static/chunks/46c31b84835d34d9.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]\n35:[\"$\",\"script\",\"script-0\",{\"src\":\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\",\"async\":true,\"nonce\":\"$undefined\"}]\n36:[\"$\",\"$L3b\",null,{\"children\":[\"$L3c\",[\"$\",\"$L3d\",null,{\"promise\":\"$@3e\"}]]}]\n37:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L3f\",null,{\"children\":\"$L40\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L41\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$42\",null,{\"fallback\":null,\"children\":\"$L43\"}]}]}]]}]\n39:[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Portfolio/_next/static/chunks/bd89afa1177e069e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]\n"])</script><script>self.__next_f.push([1,"40:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n3c:null\n"])</script><script>self.__next_f.push([1,"3e:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Portfolio - Yanis Dubois\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Generated by create next app\"}],[\"$\",\"meta\",\"2\",{\"name\":\"robots\",\"content\":\"noindex, nofollow\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"43:\"$3e:metadata\"\n"])</script></body></html>