<!DOCTYPE html><!--ngOq_SpwJEC3wOcs8SgIt--><html lang="fr"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/Portfolio/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/Portfolio/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/lineDetect.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png"/><link rel="stylesheet" href="/Portfolio/_next/static/chunks/bd89afa1177e069e.css" data-precedence="next"/><link rel="stylesheet" href="/Portfolio/_next/static/chunks/46c31b84835d34d9.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/Portfolio/_next/static/chunks/c85a7d07e7b82c9a.js"/><script src="/Portfolio/_next/static/chunks/89fec6e6de8a2578.js" async=""></script><script src="/Portfolio/_next/static/chunks/7880f8283a6f3daf.js" async=""></script><script src="/Portfolio/_next/static/chunks/5349511ac2282d68.js" async=""></script><script src="/Portfolio/_next/static/chunks/turbopack-fa6bc77bb000209b.js" async=""></script><script src="/Portfolio/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js" async=""></script><script src="/Portfolio/_next/static/chunks/c6ac08833fb371d7.js" async=""></script><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png"/><link rel="preload" as="image" href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png"/><meta name="next-size-adjust" content=""/><title>Portfolio - Yanis Dubois</title><meta name="description" content="Generated by create next app"/><meta name="robots" content="noindex, nofollow"/><script src="/Portfolio/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen text-light"><nav class="bg-dark-deep/70 backdrop-blur-sm border-b border-light-soft/10 sticky top-0 w-full p-2 text-light-soft z-5 flex justify-between"><div class="pl-2"><a href="/Portfolio">üè† <span class="hover:underline hover:text-light">Accueil</span></a><span class="text-light-dark"> / </span><a href=""><span>üìö<!-- --> </span><span class="hover:underline hover:text-light">Analyse de biblioth√®que</span></a></div><div class="pr-2"><div><div class="cursor-pointer flex justify-center text-light-soft"><p>‚öôÔ∏è <span class="pr-1">Autres projets</span></p><div class="transition-transform duration-300 ease-out rotate-0">‚ñ∏</div></div></div></div></nav><div id="nav-portal-root"></div><header class="bg-dark-soft text-light"><div class=""><div class="p-6 mx-auto max-w-5xl " style="clip-path:inset(0 0 0 0)"><h1 class="text-5xl font-bold text-center">üìö<!-- --> <!-- -->Analyse de biblioth√®que</h1></div></div></header><main><div class="bg-dark text-light-soft relative flex"><aside class="hidden lg:flex sticky top-46 h-[calc(100vh-20rem)] items-center"><div class="max-h-full overflow-hidden px-2 space-y-3 pl-6
          transition-opacity duration-300 ease-out
          opacity-100
          "></div><nav class="max-h-[70vh] w-[250px] fixed top-1/2 -translate-y-1/2 overflow-y-auto 
          bg-dark border border-light-soft/10 rounded-2xl shadow-md 
          ml-4 p-2 pt-4 pb-4 text-sm space-y-2 z-1
          transition-all duration-300 ease-out transform
          opacity-0 -translate-x-4 pointer-events-none
          "><ul class="space-y-1"></ul></nav></aside><div class="p-6 mx-auto max-w-5xl project" style="clip-path:inset(0 0 0 0)"><div><h1>Contexte</h1><hr/><div><div><p>Ce projet a √©t√© r√©alis√© dans le cadre de mon stage de fin d‚Äô√©tudes, au sein de l‚ÄôIUT d‚Äôinformatique de Gradignan. L‚Äôobjectif principal √©tait de d√©velopper une application capable de scanner et d‚Äôanalyser des photographies de biblioth√®ques (√©tag√®res remplies de livres), afin d‚Äôidentifier automatiquement les ouvrages pr√©sents √† partir des images.</p><p>Le sujet m‚Äôa √©t√© propos√© par Mathieu Raffinot, chercheur au CNRS, avec qui j‚Äôai collabor√© tout au long du stage.</p></div><div><figure><a href="/images/projects/bookshelfAnalysis/lineDetect.png"><img src="/images/projects/bookshelfAnalysis/lineDetect.png"/></a></figure></div></div><h1>Id√©e g√©n√©rale</h1><hr/><h2>Introduction</h2><p>Ce projet √©tait s√©par√© en deux parties :</p><ol type="1" start="1"><li>La premi√®re consistait √† concevoir une m√©thode de segmentation et d‚Äôanalyse d‚Äôimages de biblioth√®ques dans le but d‚Äôidentifier automatiquement les ouvrages pr√©sents, notamment √† partir de leurs tranches.</li></ol><ol type="1" start="2"><li>La seconde portait sur une t√¢che plus sp√©cifique : la modification de la police d‚Äô√©criture utilis√©e dans une application mobile Android existante, dans un souci d‚Äôaccessibilit√©.</li></ol><h2>1. Analyse de biblioth√®que</h2><p>La suite pr√©sente le prototype Python d√©velopp√© au cours du projet, en d√©taillant les diff√©rentes √©tapes cl√©s du pipeline de traitement d‚Äôimages.</p><h3>1.1 Recadrage de l‚Äôimage</h3><p>La premi√®re √©tape du processus consistait √† corriger l‚Äôorientation des images afin que les √©tag√®res apparaissent bien align√©es horizontalement. Pour cela, j‚Äôai mis en ≈ìuvre des algorithmes de d√©tection de lignes, notamment le filtre de Canny suivi de la transform√©e de Hough. Ces lignes d√©tect√©es permettent d‚Äôestimer l‚Äôinclinaison de l‚Äôimage par rapport √† l‚Äôhorizontale, et une rotation est ensuite appliqu√©e pour r√©aligner correctement l‚Äôensemble de la sc√®ne.</p><div class="grid gap-6 md:grid-cols-2"><div><figure><a href="/images/projects/bookshelfAnalysis/lineDetect.png"><img src="/images/projects/bookshelfAnalysis/lineDetect.png"/></a><figcaption>D√©tection de lignes</figcaption></figure></div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png"/></a><figcaption>Rotation</figcaption></figure></div></div><h3>1.2 S√©paration des rang√©es de livres</h3><p>Une fois l‚Äôimage redress√©e, l‚Äôobjectif suivant √©tait d‚Äôisoler les diff√©rentes rang√©es de livres pr√©sentes sur les √©tag√®res. Pour ce faire, les m√™mes techniques de d√©tection de lignes horizontales ont √©t√© utilis√©es. Les coordonn√©es de ces lignes servent de rep√®res pour d√©couper l‚Äôimage en plusieurs zones correspondant aux diff√©rentes √©tag√®res.</p><div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png"/></a><figcaption>D√©tection de lignes horizontales</figcaption></figure></div><div class="grid gap-6 md:grid-cols-2"><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png"/></a><figcaption>Premi√®re partie de la segmentation</figcaption></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png"/></a><figcaption>Seconde partie de la segmentation</figcaption></figure></div></div><h3>1.3 S√©paration des tranches de livres</h3><p>L‚Äô√©tape suivante visait √† segmenter chaque rang√©e afin d‚Äôidentifier individuellement les tranches de livres. L√† encore, des m√©thodes similaires de d√©tection de lignes, cette fois verticales, ont √©t√© appliqu√©es pour localiser les limites entre chaque ouvrage. L‚Äôimage est ensuite d√©coup√©e en sous-parties correspondant √† chaque tranche.</p><div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png"/></a><figcaption>D√©tection des lignes</figcaption></figure><h3>1.4 Nettoyage de la segmentation</h3></div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png"/></a><figcaption>Quelques tranches de livre r√©sultats</figcaption></figure></div></div><p>Une phase de traitement suppl√©mentaire a √©t√© n√©cessaire pour affiner les r√©sultats et √©liminer les √©l√©ments ind√©sirables ou parasites (fonds, ombres, objets non pertinents). Ce nettoyage repose lui aussi sur des algorithmes de d√©tection de structures lin√©aires, combin√©s √† des heuristiques pour filtrer les segments incoh√©rents.</p><div class="grid gap-6 md:grid-cols-2"><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png"/></a><figcaption>Avant nettoyage</figcaption></figure></div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png"/></a><figcaption>Apr√®s nettoyage</figcaption></figure></div></div><h3>1.5 Extraction du texte</h3><p>Une fois les tranches correctement isol√©es, l‚Äô√©tape suivante consistait √† extraire le texte visible sur celles-ci. J‚Äôai utilis√© le moteur OCR Tesseract, appliqu√© sur plusieurs versions binaris√©es de chaque images de tranche, avec diff√©rents seuils de contraste. Cette approche multi-seuils permet de maximiser les chances d‚Äôextraire les informations utiles, en contournant les variations de qualit√© ou de lisibilit√© du texte imprim√©.</p><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png"/></a><figcaption>Image originale</figcaption></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png"><img src="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png"/></a></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png"><img src="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png"/></a></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png"><img src="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png"/></a></figure><figure><a href="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png"><img src="/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png"/></a><figcaption>Image binaire avec diff√©rents seuils</figcaption></figure><p>R√©sultats obtenus :</p><blockquote>¬© | Gintbendee cxrangice Un tout petit monde David Lodge <br/>S | Bionteneoce ttrangere Un tout petit monde David Lodge<br/>Resse tian Un tout petit monde David LodgeHats<br/>g | Reaves mate Un tout petit monde David LodgeBibhotheque etrangere</blockquote><h3>1.6 Traitement des r√©sultats textuels</h3><p>Le texte brut issu de l‚ÄôOCR contient souvent du bruit : erreurs de reconnaissance, caract√®res sp√©ciaux, coupures. Un post-traitement a donc √©t√© mis en place pour nettoyer ces r√©sultats. Il comprend la suppression des caract√®res non alphanum√©riques, ainsi qu‚Äôun filtrage destin√© √† isoler les cha√Ænes de texte les plus pertinentes.</p><p>R√©sultats obtenus :</p><blockquote>Un tout petit monde David Lodge</blockquote><h3>1.7 Validation via interrogation en ligne</h3><p>Afin de s‚Äôassurer d‚Äôavoir une information viable, on a ensuite d√©cid√© d‚Äôinterroger Google en utilisant Selenium, ce qui nous a permis de naviguer en headless sur internet. On cr√©e une requ√™te avec Selenium contenant le r√©sultat obtenu dans l‚Äô√©tape pr√©c√©dente, et l‚Äôon re√ßoit alors le titre exacte accompagn√© du nom de l‚Äôauteur.</p><p>Pour fiabiliser les informations extraites, une validation automatique a √©t√© ajout√©e en fin de cha√Æne. √Ä l‚Äôaide de Selenium, une requ√™te web est g√©n√©r√©e √† partir du texte obtenu, puis envoy√©e √† Google en mode headless. La r√©ponse est ensuite analys√©e afin de r√©cup√©rer le titre exact de l‚Äôouvrage, ainsi que, lorsque c‚Äôest possible, le nom de l‚Äôauteur. Cette √©tape permet de compenser les √©ventuelles erreurs de l‚ÄôOCR en s‚Äôappuyant sur des sources d‚Äôinformation externes.</p><h2>2. Changement de police d‚Äô√©criture</h2><p>La seconde partie du projet consistait √† ajouter une fonctionnalit√© de personnalisation de la police d‚Äô√©criture dans l‚Äôapplication open source TextFairy, d√©di√©e √† la reconnaissance optique de caract√®res (OCR) sur Android.</p><p>Bien que cette t√¢che puisse para√Ætre simple en apparence, elle s‚Äôest r√©v√©l√©e plus technique qu‚Äôanticip√©, en raison de la complexit√© de l‚Äôarchitecture de l‚Äôapplication et des sp√©cificit√©s du d√©veloppement Android. Le travail a √©t√© r√©alis√© sous Android Studio, en manipulant les ressources d‚Äôinterface, les fichiers XML de styles, et les m√©canismes de gestion de th√®mes pour int√©grer le changement de typographie de mani√®re propre et fonctionnelle.</p><div class="grid gap-6 md:grid-cols-2"><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png"/></a><figcaption>Avant application de la police</figcaption></figure></div><div><figure><a href="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png"><img src="/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png"/></a><figcaption>Apr√®s application de la police</figcaption></figure></div></div><h1>Ressources suppl√©mentaires</h1><hr/></div><div class="grid gap-6 md:grid-cols-2"><div class="font-bold text-light text-center"><a class="flex justify-center items-center" href="https://github.com/yanis-dubois/BookShelfAnalyse"><img alt="" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="w-[1rem] h-[1rem]" style="color:transparent" src="/images/icons/Git_icon.png"/>¬†<span class="underline">Acc√©dez au code source ‚Üí</span></a></div><div class="font-bold text-light text-center"><a href="https://drive.google.com/file/d/1A0NbOEAv3ft5B_GCygAvZErcZi5LReBw/view?usp=share_link">üìÑ<!-- --> <span class="underline">Consultez le rapport PDF ‚Üí</span></a></div></div></div></div></main><footer class="bg-dark-soft p-6 text-center text-sm text-light-dark">¬© 2025 Yanis Dubois ‚Äî Libre et Open Source, h√©berg√© via GitHub Pages<br/>Cr√©dits : image #Comp√©tences - Unsplash ; image #Loisirs - Scavengers Reign par Joseph Bennett et Charles Huettner</footer></div><!--$--><!--/$--><script src="/Portfolio/_next/static/chunks/c85a7d07e7b82c9a.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[39756,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"default\"]\n3:I[37457,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"default\"]\n4:I[22016,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\"],\"default\"]\n5:I[72334,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\"],\"ProjectsNav\"]\n6:I[72334,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\"],\"TableOfContents\"]\n38:I[68027,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"default\"]\n:HL[\"/Portfolio/_next/static/chunks/bd89afa1177e069e.css\",\"style\"]\n:HL[\"/Portfolio/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/Portfolio/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/Portfolio/_next/static/chunks/46c31b84835d34d9.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"ngOq-SpwJEC3wOcs8SgIt\",\"p\":\"/Portfolio\",\"c\":[\"\",\"projects\",\"bookshelfAnalysis\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"projects\",{\"children\":[\"bookshelfAnalysis\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Portfolio/_next/static/chunks/bd89afa1177e069e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"fr\",\"children\":[\"$\",\"body\",null,{\"className\":\"geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"projects\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"bookshelfAnalysis\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen text-light\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"bg-dark-deep/70 backdrop-blur-sm border-b border-light-soft/10 sticky top-0 w-full p-2 text-light-soft z-5 flex justify-between\",\"children\":[[\"$\",\"div\",null,{\"className\":\"pl-2\",\"children\":[[\"$\",\"$L4\",null,{\"href\":\"/\",\"children\":[\"üè† \",[\"$\",\"span\",null,{\"className\":\"hover:underline hover:text-light\",\"children\":\"Accueil\"}]]}],[\"$\",\"span\",null,{\"className\":\"text-light-dark\",\"children\":\" / \"}],[\"$\",\"$L4\",null,{\"href\":\"\",\"children\":[[\"$\",\"span\",null,{\"children\":[\"üìö\",\" \"]}],[\"$\",\"span\",null,{\"className\":\"hover:underline hover:text-light\",\"children\":\"Analyse de biblioth√®que\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"pr-2\",\"children\":[\"$\",\"$L5\",null,{}]}]]}],[\"$\",\"div\",null,{\"id\":\"nav-portal-root\"}],[\"$\",\"header\",null,{\"className\":\"bg-dark-soft text-light\",\"children\":[\"$\",\"div\",null,{\"className\":\"\",\"style\":{},\"id\":\"$undefined\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-6 mx-auto max-w-5xl \",\"style\":{\"clipPath\":\"inset(0 0 0 0)\"},\"children\":[\"$\",\"h1\",null,{\"className\":\"text-5xl font-bold text-center\",\"children\":[\"üìö\",\" \",\"Analyse de biblioth√®que\"]}]}]}]}],[\"$\",\"main\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"bg-dark text-light-soft relative flex\",\"style\":{},\"id\":\"$undefined\",\"children\":[[\"$\",\"$L6\",null,{}],[\"$\",\"div\",null,{\"className\":\"p-6 mx-auto max-w-5xl project\",\"style\":{\"clipPath\":\"inset(0 0 0 0)\"},\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h1\",null,{\"children\":\"Contexte\"}],[\"$\",\"hr\",null,{}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"p\",null,{\"children\":\"Ce projet a √©t√© r√©alis√© dans le cadre de mon stage de fin d‚Äô√©tudes, au sein de l‚ÄôIUT d‚Äôinformatique de Gradignan. L‚Äôobjectif principal √©tait de d√©velopper une application capable de scanner et d‚Äôanalyser des photographies de biblioth√®ques (√©tag√®res remplies de livres), afin d‚Äôidentifier automatiquement les ouvrages pr√©sents √† partir des images.\"}],\"$L7\"]}],\"$L8\"]}],\"$L9\",\"$La\",\"$Lb\",\"$Lc\",\"$Ld\",\"$Le\",\"$Lf\",\"$L10\",\"$L11\",\"$L12\",\"$L13\",\"$L14\",\"$L15\",\"$L16\",\"$L17\",\"$L18\",\"$L19\",\"$L1a\",\"$L1b\",\"$L1c\",\"$L1d\",\"$L1e\",\"$L1f\",\"$L20\",\"$L21\",\"$L22\",\"$L23\",\"$L24\",\"$L25\",\"$L26\",\"$L27\",\"$L28\",\"$L29\",\"$L2a\",\"$L2b\",\"$L2c\",\"$L2d\",\"$L2e\",\"$L2f\",\"$L30\",\"$L31\"]}],\"$L32\"]}]]}]}],\"$L33\"]}],[\"$L34\",\"$L35\"],\"$L36\"]}],{},null,false]},null,false]},null,false]},null,false],\"$L37\",false]],\"m\":\"$undefined\",\"G\":[\"$38\",[\"$L39\"]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"3a:I[5500,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\",\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\"],\"Image\"]\n3b:I[97367,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"OutletBoundary\"]\n3d:I[11533,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"AsyncMetadataOutlet\"]\n3f:I[97367,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"ViewportBoundary\"]\n41:I[97367,[\"/Portfolio/_next/static/chunks/ff1a16fafef87110.js\",\"/Portfolio/_next/static/chunks/7dd66bdf8a7e5707.js\"],\"MetadataBoundary\"]\n42:\"$Sreact.suspense\"\n7:[\"$\",\"p\",null,{\"children\":\"Le sujet m‚Äôa √©t√© propos√© par Mathieu Raffinot, chercheur au CNRS, avec qui j‚Äôai collabor√© tout au long du stage.\"}]\n8:[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/lineDetect.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/lineDetect.png\"}]}]}]}]\n9:[\"$\",\"h1\",null,{\"children\":\"Id√©e g√©n√©rale\"}]\na:[\"$\",\"hr\",null,{}]\nb:[\"$\",\"h2\",null,{\"children\":\"Introduction\"}]\nc:[\"$\",\"p\",null,{\"children\":\"Ce projet √©tait s√©par√© en deux parties :\"}]\nd:[\"$\",\"ol\",null,{\"type\":\"1\",\"start\":\"1\",\"children\":[\"$\",\"li\",null,{\"children\":\"La premi√®re consistait √† concevoir une m√©thode de segmentation et d‚Äôanalyse d‚Äôimages de biblioth√®ques dans le but d‚Äôidentifier automatiquement les ouvrages pr√©sents, notamment √† partir de leurs tranches.\"}]}]\ne:[\"$\",\"ol\",null,{\"type\":\"1\",\"start\":\"2\",\"children\":[\"$\",\"li\",null,{\"children\":\"La seconde portait sur une t√¢che plus sp√©cifique : la modification de la police d‚Äô√©criture utilis√©e dans une application mobile Android existante, dans un souci d‚Äôaccessibilit√©.\"}]}]\nf:[\"$\",\"h2\",null,{\"children\":\"1. Analyse de biblioth√®que\"}]\n10:[\"$\",\"p\",null,{\"children\":\"La suite pr√©sente le prototype Python d√©velopp√©"])</script><script>self.__next_f.push([1," au cours du projet, en d√©taillant les diff√©rentes √©tapes cl√©s du pipeline de traitement d‚Äôimages.\"}]\n11:[\"$\",\"h3\",null,{\"children\":\"1.1 Recadrage de l‚Äôimage\"}]\n12:[\"$\",\"p\",null,{\"children\":\"La premi√®re √©tape du processus consistait √† corriger l‚Äôorientation des images afin que les √©tag√®res apparaissent bien align√©es horizontalement. Pour cela, j‚Äôai mis en ≈ìuvre des algorithmes de d√©tection de lignes, notamment le filtre de Canny suivi de la transform√©e de Hough. Ces lignes d√©tect√©es permettent d‚Äôestimer l‚Äôinclinaison de l‚Äôimage par rapport √† l‚Äôhorizontale, et une rotation est ensuite appliqu√©e pour r√©aligner correctement l‚Äôensemble de la sc√®ne.\"}]\n"])</script><script>self.__next_f.push([1,"13:[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/lineDetect.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/lineDetect.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"D√©tection de lignes\"}]]}]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.38.10.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Rotation\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"14:[\"$\",\"h3\",null,{\"children\":\"1.2 S√©paration des rang√©es de livres\"}]\n15:[\"$\",\"p\",null,{\"children\":\"Une fois l‚Äôimage redress√©e, l‚Äôobjectif suivant √©tait d‚Äôisoler les diff√©rentes rang√©es de livres pr√©sentes sur les √©tag√®res. Pour ce faire, les m√™mes techniques de d√©tection de lignes horizontales ont √©t√© utilis√©es. Les coordonn√©es de ces lignes servent de rep√®res pour d√©couper l‚Äôimage en plusieurs zones correspondant aux diff√©rentes √©tag√®res.\"}]\n"])</script><script>self.__next_f.push([1,"16:[\"$\",\"div\",null,{\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.40.48.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"D√©tection de lignes horizontales\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.00.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Premi√®re partie de la segmentation\"}]]}],[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-22__19.41.09.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Seconde partie de la segmentation\"}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"17:[\"$\",\"h3\",null,{\"children\":\"1.3 S√©paration des tranches de livres\"}]\n18:[\"$\",\"p\",null,{\"children\":\"L‚Äô√©tape suivante visait √† segmenter chaque rang√©e afin d‚Äôidentifier individuellement les tranches de livres. L√† encore, des m√©thodes similaires de d√©tection de lignes, cette fois verticales, ont √©t√© appliqu√©es pour localiser les limites entre chaque ouvrage. L‚Äôimage est ensuite d√©coup√©e en sous-parties correspondant √† chaque tranche.\"}]\n"])</script><script>self.__next_f.push([1,"19:[\"$\",\"div\",null,{\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__09.32.11.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"D√©tection des lignes\"}]]}],[\"$\",\"h3\",null,{\"children\":\"1.4 Nettoyage de la segmentation\"}]]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2023-07-27__20.29.31.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Quelques tranches de livre r√©sultats\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"1a:[\"$\",\"p\",null,{\"children\":\"Une phase de traitement suppl√©mentaire a √©t√© n√©cessaire pour affiner les r√©sultats et √©liminer les √©l√©ments ind√©sirables ou parasites (fonds, ombres, objets non pertinents). Ce nettoyage repose lui aussi sur des algorithmes de d√©tection de structures lin√©aires, combin√©s √† des heuristiques pour filtrer les segments incoh√©rents.\"}]\n"])</script><script>self.__next_f.push([1,"1b:[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.21.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Avant nettoyage\"}]]}]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.19.43.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Apr√®s nettoyage\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"1c:[\"$\",\"h3\",null,{\"children\":\"1.5 Extraction du texte\"}]\n1d:[\"$\",\"p\",null,{\"children\":\"Une fois les tranches correctement isol√©es, l‚Äô√©tape suivante consistait √† extraire le texte visible sur celles-ci. J‚Äôai utilis√© le moteur OCR Tesseract, appliqu√© sur plusieurs versions binaris√©es de chaque images de tranche, avec diff√©rents seuils de contraste. Cette approche multi-seuils permet de maximiser les chances d‚Äôextraire les informations utiles, en contournant les variations de qualit√© ou de lisibilit√© du texte imprim√©.\"}]\n1e:[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-23__12.55.15.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Image originale\"}]]}]\n1f:[\"$\",\"figure\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.54.png\"}]}]}]\n20:[\"$\",\"figure\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_13.09.25.png\"}]}]}]\n21:[\"$\",\"figure\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.55.47.png\"}]}]}]\n22:[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_decran_2021-06-23_a_12.56.04.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Image binaire avec diff√©rents seuils\"}]]}]\n23:[\"$\",\"p\",null,{\"children\":\"R√©sultats obtenus :\"}]\n24:[\"$\",\"blockquote\",null,{\"children\":[\"¬© | Gintbendee cxran"])</script><script>self.__next_f.push([1,"gice Un tout petit monde David Lodge \",[\"$\",\"br\",null,{}],\"S | Bionteneoce ttrangere Un tout petit monde David Lodge\",[\"$\",\"br\",null,{}],\"Resse tian Un tout petit monde David LodgeHats\",[\"$\",\"br\",null,{}],\"g | Reaves mate Un tout petit monde David LodgeBibhotheque etrangere\"]}]\n25:[\"$\",\"h3\",null,{\"children\":\"1.6 Traitement des r√©sultats textuels\"}]\n26:[\"$\",\"p\",null,{\"children\":\"Le texte brut issu de l‚ÄôOCR contient souvent du bruit : erreurs de reconnaissance, caract√®res sp√©ciaux, coupures. Un post-traitement a donc √©t√© mis en place pour nettoyer ces r√©sultats. Il comprend la suppression des caract√®res non alphanum√©riques, ainsi qu‚Äôun filtrage destin√© √† isoler les cha√Ænes de texte les plus pertinentes.\"}]\n27:[\"$\",\"p\",null,{\"children\":\"R√©sultats obtenus :\"}]\n28:[\"$\",\"blockquote\",null,{\"children\":\"Un tout petit monde David Lodge\"}]\n29:[\"$\",\"h3\",null,{\"children\":\"1.7 Validation via interrogation en ligne\"}]\n2a:[\"$\",\"p\",null,{\"children\":\"Afin de s‚Äôassurer d‚Äôavoir une information viable, on a ensuite d√©cid√© d‚Äôinterroger Google en utilisant Selenium, ce qui nous a permis de naviguer en headless sur internet. On cr√©e une requ√™te avec Selenium contenant le r√©sultat obtenu dans l‚Äô√©tape pr√©c√©dente, et l‚Äôon re√ßoit alors le titre exacte accompagn√© du nom de l‚Äôauteur.\"}]\n2b:[\"$\",\"p\",null,{\"children\":\"Pour fiabiliser les informations extraites, une validation automatique a √©t√© ajout√©e en fin de cha√Æne. √Ä l‚Äôaide de Selenium, une requ√™te web est g√©n√©r√©e √† partir du texte obtenu, puis envoy√©e √† Google en mode headless. La r√©ponse est ensuite analys√©e afin de r√©cup√©rer le titre exact de l‚Äôouvrage, ainsi que, lorsque c‚Äôest possible, le nom de l‚Äôauteur. Cette √©tape permet de compenser les √©ventuelles erreurs de l‚ÄôOCR en s‚Äôappuyant sur des sources d‚Äôinformation externes.\"}]\n2c:[\"$\",\"h2\",null,{\"children\":\"2. Changement de police d‚Äô√©criture\"}]\n2d:[\"$\",\"p\",null,{\"children\":\"La seconde partie du projet consistait √† ajouter une fonctionnalit√© de personnalisation de "])</script><script>self.__next_f.push([1,"la police d‚Äô√©criture dans l‚Äôapplication open source TextFairy, d√©di√©e √† la reconnaissance optique de caract√®res (OCR) sur Android.\"}]\n2e:[\"$\",\"p\",null,{\"children\":\"Bien que cette t√¢che puisse para√Ætre simple en apparence, elle s‚Äôest r√©v√©l√©e plus technique qu‚Äôanticip√©, en raison de la complexit√© de l‚Äôarchitecture de l‚Äôapplication et des sp√©cificit√©s du d√©veloppement Android. Le travail a √©t√© r√©alis√© sous Android Studio, en manipulant les ressources d‚Äôinterface, les fichiers XML de styles, et les m√©canismes de gestion de th√®mes pour int√©grer le changement de typographie de mani√®re propre et fonctionnelle.\"}]\n"])</script><script>self.__next_f.push([1,"2f:[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__15.00.32.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Avant application de la police\"}]]}]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"figure\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png\",\"children\":[\"$\",\"img\",null,{\"src\":\"/images/projects/bookshelfAnalysis/Capture_dcran_2021-06-24__17.26.30.png\"}]}],[\"$\",\"figcaption\",null,{\"children\":\"Apr√®s application de la police\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"30:[\"$\",\"h1\",null,{\"children\":\"Ressources suppl√©mentaires\"}]\n31:[\"$\",\"hr\",null,{}]\n"])</script><script>self.__next_f.push([1,"32:[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"font-bold text-light text-center\",\"children\":[\"$\",\"$L4\",null,{\"href\":\"https://github.com/yanis-dubois/BookShelfAnalyse\",\"className\":\"flex justify-center items-center\",\"children\":[[\"$\",\"$L3a\",null,{\"src\":\"/images/icons/Git_icon.png\",\"alt\":\"\",\"width\":32,\"height\":32,\"className\":\"w-[1rem] h-[1rem]\"}],\"¬†\",[\"$\",\"span\",null,{\"className\":\"underline\",\"children\":\"Acc√©dez au code source ‚Üí\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"font-bold text-light text-center\",\"children\":[\"$\",\"$L4\",null,{\"href\":\"https://drive.google.com/file/d/1A0NbOEAv3ft5B_GCygAvZErcZi5LReBw/view?usp=share_link\",\"children\":[\"üìÑ\",\" \",[\"$\",\"span\",null,{\"className\":\"underline\",\"children\":\"Consultez le rapport PDF ‚Üí\"}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"33:[\"$\",\"footer\",null,{\"className\":\"bg-dark-soft p-6 text-center text-sm text-light-dark\",\"children\":[\"¬© 2025 Yanis Dubois ‚Äî Libre et Open Source, h√©berg√© via GitHub Pages\",[\"$\",\"br\",null,{}],\"Cr√©dits : image #Comp√©tences - Unsplash ; image #Loisirs - Scavengers Reign par Joseph Bennett et Charles Huettner\"]}]\n34:[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Portfolio/_next/static/chunks/46c31b84835d34d9.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]\n35:[\"$\",\"script\",\"script-0\",{\"src\":\"/Portfolio/_next/static/chunks/c6ac08833fb371d7.js\",\"async\":true,\"nonce\":\"$undefined\"}]\n36:[\"$\",\"$L3b\",null,{\"children\":[\"$L3c\",[\"$\",\"$L3d\",null,{\"promise\":\"$@3e\"}]]}]\n37:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L3f\",null,{\"children\":\"$L40\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L41\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$42\",null,{\"fallback\":null,\"children\":\"$L43\"}]}]}]]}]\n39:[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Portfolio/_next/static/chunks/bd89afa1177e069e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]\n"])</script><script>self.__next_f.push([1,"40:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n3c:null\n"])</script><script>self.__next_f.push([1,"3e:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Portfolio - Yanis Dubois\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Generated by create next app\"}],[\"$\",\"meta\",\"2\",{\"name\":\"robots\",\"content\":\"noindex, nofollow\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"43:\"$3e:metadata\"\n"])</script></body></html>